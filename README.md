# Azure AI Foundry Chat Application

> **Disclaimer:** All files in this repository are generated by GitHub Copilot.

This project provides a Streamlit-based chat interface integrated with Azure OpenAI services. It allows users to interact with various Azure AI models, upload context files (text, PDF, images), and receive AI-generated responses.

## Features

- Interactive chat interface powered by Streamlit.
- Integration with Azure OpenAI models (GPT-3.5 Turbo, GPT-4o, Deepseek-R1, O3 Mini).
- Supports uploading context files (text, PDF, images) for enhanced interactions.

## Prerequisites

- Docker installed locally ([Docker Desktop](https://www.docker.com/products/docker-desktop/)).
- Azure subscription with access to Azure OpenAI services.
- Azure CLI installed ([Azure CLI](https://docs.microsoft.com/cli/azure/install-azure-cli)).

## Environment Variables

Ensure you have the following environment variables set:

- `AZURE_OPENAI_ENDPOINT`: Your Azure OpenAI endpoint URL.
- `AZURE_OPENAI_API_KEY`: Your Azure OpenAI API key.

## Building and Running Locally with Docker

1. **Build the Docker image**:

```bash
docker build -t azure-ai-chat-app .
```

2. **Run the Docker container locally**:

```bash
docker run -p 8501:8501 -e AZURE_OPENAI_ENDPOINT="<your-endpoint>" -e AZURE_OPENAI_API_KEY="<your-api-key>" azure-ai-chat-app
```

3. **Access the application**:

Open your browser and navigate to:

```
http://localhost:8501
```

## Pushing to Container Registries

### Pushing to DockerHub

1. **Log in to DockerHub**:

```bash
docker login
```

2. **Tag your image with your DockerHub username**:

```bash
docker tag azure-ai-chat-app <your-dockerhub-username>/azure-ai-chat-app:latest
```

3. **Push the image to DockerHub**:

```bash
docker push <your-dockerhub-username>/azure-ai-chat-app:latest
```

### Pushing to Azure Container Registry (ACR)

1. **Create a resource group (if not already created)**:

```bash
az group create --name <your-resource-group> --location <your-location>
```

2. **Create an Azure Container Registry (if not already created)**:

```bash
az acr create --resource-group <your-resource-group> --name <your-acr-name> --sku Basic
```

3. **Log in to your ACR**:

```bash
az acr login --name <your-acr-name>
```

4. **Tag your image with the ACR login server name**:

```bash
docker tag azure-ai-chat-app <your-acr-name>.azurecr.io/azure-ai-chat-app:latest
```

5. **Push the image to ACR**:

```bash
docker push <your-acr-name>.azurecr.io/azure-ai-chat-app:latest
```

6. **Use the ACR image in your deployment**:

When deploying to ACI using the Bicep template, use the full image path:

```bash
az deployment group create \
  --resource-group <your-resource-group> \
  --template-file infra/aci.bicep \
  --parameters image="<your-acr-name>.azurecr.io/azure-ai-chat-app:latest" azureOpenAIEndpoint="<your-endpoint>" azureOpenAIAPIKey="<your-api-key>"
```

> Note: If your ACR has private access, you'll need to provide credentials for ACI to pull the image. Add the following parameters to your deployment command:

```bash
--parameters registryServer="<your-acr-name>.azurecr.io" registryUsername="<registry-username>" registryPassword="<registry-password>"
```

You can get the credentials using:
```bash
az acr credential show --name <your-acr-name>
```

## Deploying to Azure Container Instances (ACI)

1. **Log in to Azure CLI**:

```bash
az login
```

2. **Create a resource group (if not already created)**:

```bash
az group create --name <your-resource-group> --location <your-location>
```

3. **Deploy using Bicep template** (`infra/aci.bicep`):

```bash
az deployment group create \
  --resource-group <your-resource-group> \
  --template-file infra/aci.bicep \
  --parameters image="<your-docker-image>" azureOpenAIEndpoint="<your-endpoint>" azureOpenAIAPIKey="<your-api-key>"
```

Replace placeholders (`<your-resource-group>`, `<your-location>`, `<your-docker-image>`, `<your-endpoint>`, `<your-api-key>`) with your actual values.

If using an image from a private ACR, add registry credentials to your deployment:

```bash
az deployment group create \
  --resource-group <your-resource-group> \
  --template-file infra/aci.bicep \
  --parameters image="<your-acr-name>.azurecr.io/azure-ai-chat-app:latest" \
               azureOpenAIEndpoint="<your-endpoint>" \
               azureOpenAIAPIKey="<your-api-key>" \
               registryServer="<your-acr-name>.azurecr.io" \
               registryUsername="<registry-username>" \
               registryPassword="<registry-password>"
```

4. **Access the deployed application**:

After deployment, the fully qualified domain name (FQDN) will be displayed. Access your application at:

```
http://<your-container-group-name>.<region>.azurecontainer.io:8501
```

## Original Prompts
> Create a Python web app using Streamlit that allows me to call an Azure AI Foundry Endpoint to chat with. I want the user to be able to select a model (listed in a parameter in the app to make sure the developer has a choice which models are allowed). Provide the ability to upload a text file, PDF or image for context in the chat. The endpoint and API key should be configurable using an environment variable but also provide an input option in the web app itself so it can be changed at runtime.

> Create a README file for Github using Markup. Please add documentation about the project, also add instructions on how to build the docker file and run it locally next to the instructions on how to run this to Azure Container Instances. Feel free to add this prompt to the readme too.

> Create a bicep and a terraform file to deploy the Azure Container Intances.

> Can you add a Github Action to the project to build the docker container and push it to either Docker Hub or and Azure Container Registry? I assume you will need some secrets in the Github Action to make that work. Can you add the necessary steps to make sure this Github Action is only triggered on the main branch and that only I can merge changes into the main branch to prevent abuse?